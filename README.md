# ml-chat

## ü§ñ Chatbot de Artigos Cient√≠ficos (Data Science & Machine Learning) com Azure AI Foundry

### Vis√£o Geral do Projeto

Este projeto demonstra a constru√ß√£o de um Chatbot de Perguntas e Respostas (Q&A) baseado em documentos, utilizando a arquitetura de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG). O objetivo √© criar um assistente virtual capaz de responder a perguntas complexas, fundamentando suas respostas exclusivamente no conte√∫do de artigos cient√≠ficos sobre Ci√™ncia de Dados (Data Science) e Aprendizado de M√°quina (Machine Learning).

O desenvolvimento simula o uso do Azure AI Foundry e seus Playgrounds para indexar o conhecimento e realizar o deploy do chat como um Web App.

### Cen√°rio

Imagine um estudante de Engenharia de Software elaborando seu Trabalho de Conclus√£o de Curso (TCC). A pesquisa exige a correla√ß√£o de informa√ß√µes de dezenas de artigos cient√≠ficos. Em vez de ler e reler manualmente, este projeto prop√µe uma solu√ß√£o de IA para interpretar os PDFs, organizar as informa√ß√µes e gerar respostas contextuais a partir desse conjunto de dados propriet√°rio.

## ‚öôÔ∏è Conceitos T√©cnicos Chave

O cora√ß√£o deste chatbot reside na arquitetura RAG, que combina a capacidade generativa de um Large Language Model (LLM) com a precis√£o de um sistema de recupera√ß√£o de informa√ß√µes.

| Conceito | Descri√ß√£o | Aplica√ß√£o no chatbot |
|--|--|--|
| Embeddings | Representa√ß√µes num√©ricas de texto em um espa√ßo vetorial de alta dimens√£o. Textos com significado similar s√£o mapeados para vetores pr√≥ximos. | O conte√∫do dos artigos (simulado em inputs/documento.txt) √© transformado em vetores para indexa√ß√£o.|
| Busca Vetorial | M√©todo para encontrar vetores que s√£o semanticamente mais pr√≥ximos de um vetor de consulta. | Quando o usu√°rio pergunta, a pergunta √© vetorizada e usada para buscar os trechos de artigos mais relevantes no Banco de Dados Vetorial. |
| RAG (Retrieval-Augmented Generation) | Uma t√©cnica que recupera informa√ß√µes de uma fonte de dados externa e as utiliza como contexto para guiar a resposta do LLM. | O LLM (ex: GPT-4o no Azure AI Foundry) recebe a pergunta do usu√°rio mais os trechos recuperados (contexto), garantindo respostas factuais e baseadas nas fontes. |


## üõ†Ô∏è Processo no Azure AI Foundry

O processo de cria√ß√£o do chatbot no Azure AI Foundry envolveu as seguintes etapas:

1. Cria√ß√£o do Projeto e Sele√ß√£o do Modelo

  ‚Ä¢ A√ß√£o: Cria√ß√£o de um novo projeto no portal do Azure AI Foundry.

  ‚Ä¢ Modelo: Sele√ß√£o do gpt-4o como o modelo base para a gera√ß√£o de respostas.

  ‚Ä¢ Recurso: Configura√ß√£o de um recurso Azure AI Foundry, que gerencia o acesso ao modelo e aos servi√ßos de IA.


Configura√ß√£o Inicial do Projeto no Azure AI Foundry, na qual o modelo GPT-4o √© selecionado e um nome (ex: "RAG-DS-ML-Chat") √© definido. Detalhamento:

  ‚Ä¢ Modelo: gpt-4o (Deployment: Global standard)

  ‚Ä¢ Nome do Projeto: RAG-DS-ML-Chat

  ‚Ä¢ Recurso de IA: Novo recurso criado na regi√£o "East US" (recomendada para cotas). ```

2. Ingest√£o de Dados e Indexa√ß√£o (RAG)

  ‚Ä¢ A√ß√£o: Utiliza√ß√£o do recurso de Data Ingestion (ou Knowledge no Playground) para carregar os documentos.

  ‚Ä¢ Documentos: Carregamento dos arquivos PDF (simulados pelo inputs/documento.txt).

  ‚Ä¢ Processamento: O Azure AI Foundry automaticamente gera os embeddings dos documentos e os armazena em um √≠ndice vetorial (ex: Azure AI Search).
  

Indexa√ß√£o de Conhecimento

Configura√ß√£o da Fonte de Dados (Knowledge). Descri√ß√£o: se√ß√£o onde os documentos s√£o carregados e o √≠ndice vetorial √© criado/atualizado. Detalhamento:

  ‚Ä¢ Fonte de Dados: Upload de Arquivos (3 PDFs sobre Transformer, RL e Bancos Vetoriais)

  ‚Ä¢ Status: Indexa√ß√£o Completa (3/3 documentos processados)

  ‚Ä¢ √çndice Vetorial: ai-search-rag-index

  ‚Ä¢ Op√ß√£o RAG: Ativada (Search Type: Vector and Hybrid)

3. Teste no Chat Playground

  ‚Ä¢ A√ß√£o: Uso do Chat Playground para testar o chatbot com o contexto dos documentos.

  ‚Ä¢ Instru√ß√£o de Sistema (System Prompt): Definir o papel do chatbot, por exemplo: "Voc√™ √© um assistente de pesquisa especializado em Ci√™ncia de Dados e Machine Learning. Suas respostas devem ser estritamente baseadas nos documentos fornecidos."


Intera√ß√£o e Resposta Contextualizada

| Pergunta do Usu√°rio | Resposta do Chatbot (Simulada) | Trechos Recuperados (Simulados) |
| -- | -- | -- | 
|Qual a import√¢ncia dos Bancos de Dados Vetoriais para a arquitetura RAG? | Bancos de Dados Vetoriais s√£o essenciais para a implementa√ß√£o eficiente de RAG. Eles armazenam embeddings e permitem a busca de similaridade de vetores em alta velocidade. Isso garante que a resposta do LLM seja fundamentada no conte√∫do espec√≠fico fornecido, recuperando os trechos mais semanticamente relevantes ap√≥s a vetoriza√ß√£o da consulta. | "Bancos de Dados Vetoriais (Vector Databases) s√£o essenciais para a implementa√ß√£o eficiente de RAG. Eles armazenam embeddings..." |
| O que o mecanismo de auto-aten√ß√£o permitiu na arquitetura Transformer? | O mecanismo de auto-aten√ß√£o (self-attention), introduzido pela arquitetura Transformer, revolucionou o PLN ao permitir que o modelo pondere a import√¢ncia de diferentes palavras na sequ√™ncia de entrada, independentemente de sua dist√¢ncia. | "A arquitetura Transformer revolucionou o Processamento de Linguagem Natural (PLN) ao introduzir o mecanismo de auto-aten√ß√£o..." |


4. Deploy como Web App

   ‚Ä¢ A√ß√£o: Publica√ß√£o do projeto como um Web App atrav√©s do recurso de Deploy no Azure AI Foundry.

   ‚Ä¢ Resultado: Um endpoint p√∫blico para o chatbot, permitindo que qualquer pessoa interaja com ele via navegador.

üí° Insights e Possibilidades

A constru√ß√£o deste chatbot RAG trouxe insights valiosos sobre a aplica√ß√£o pr√°tica de IA Generativa em cen√°rios de pesquisa:

1. Precis√£o e Redu√ß√£o de Alucina√ß√µes: A maior vantagem do RAG √© a capacidade de ancorar a resposta do LLM em fatos concretos (os artigos carregados), minimizando as "alucina√ß√µes" (respostas incorretas ou inventadas) comuns em modelos puramente generativos.

2. Conhecimento Propriet√°rio: O sistema permite criar um modelo de assist√™ncia virtual focado em um conjunto de informa√ß√µes propriet√°rias, como documentos internos de uma empresa ou, neste caso, a bibliografia espec√≠fica de um TCC.

3. Escalabilidade: O uso de servi√ßos gerenciados como o Azure AI Search (para o √≠ndice vetorial) e o Azure AI Foundry simplifica a escalabilidade do sistema para lidar com milhares de documentos e milh√µes de consultas.

4. Aplica√ß√µes Futuras: Este modelo pode ser expandido para:

  ‚Ä¢ An√°lise de Contratos: Resumir cl√°usulas e responder a perguntas sobre termos legais.

  ‚Ä¢ Suporte T√©cnico: Criar um help desk automatizado baseado em manuais e logs de erro.

  ‚Ä¢ Educa√ß√£o: Criar assistentes de estudo personalizados para materiais did√°ticos espec√≠ficos.



## üìÇ Estrutura do Reposit√≥rio

``` azure-ai-chatbot-rag-ds-ml/ ‚îú‚îÄ‚îÄ inputs/ ‚îÇ ‚îî‚îÄ‚îÄ documento.txt (Simula√ß√£o do conte√∫do dos artigos cient√≠ficos) ‚îî‚îÄ‚îÄ README.md (Este arquivo de documenta√ß√£o) ```


**[Link para o ml-chat)](https://ml-chat.azurewebsites.net/)**
